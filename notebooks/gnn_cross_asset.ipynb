{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "title_header"
   },
   "source": [
    "# Snowcore Anomaly Detection - Cross-Asset GNN Model\n",
    "\n",
    "This notebook implements a Graph Neural Network (GNN) for anomaly propagation prediction across the Avalanche X1 production line.\n",
    "\n",
    "## Objective\n",
    "Predict which downstream assets will show anomalies given upstream sensor drift, using a GraphSAGE architecture with temporal attention.\n",
    "\n",
    "## Graph Structure\n",
    "```\n",
    "LAYUP_ROOM (ENV) ────────────────────────────────────────→\n",
    "       │\n",
    "LAYUP_BOT_01 → AUTOCLAVE_01 → CNC_MILL_01 → QC_STATION_01\n",
    "LAYUP_BOT_02 → AUTOCLAVE_02 → CNC_MILL_02 → QC_STATION_02\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "imports_cell"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"Installing PyTorch and torch_geometric...\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"torch\", \"torch_geometric\"], check=True)\n",
    "print(\"Installation complete!\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "graph_structure_header"
   },
   "source": [
    "## 1. Define Graph Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "define_graph_cell"
   },
   "outputs": [],
   "source": [
    "ASSETS = [\n",
    "    'LAYUP_ROOM', 'LAYUP_BOT_01', 'LAYUP_BOT_02', \n",
    "    'AUTOCLAVE_01', 'AUTOCLAVE_02',\n",
    "    'CNC_MILL_01', 'CNC_MILL_02',\n",
    "    'QC_STATION_01', 'QC_STATION_02'\n",
    "]\n",
    "\n",
    "ASSET_TO_IDX = {asset: i for i, asset in enumerate(ASSETS)}\n",
    "\n",
    "EDGES = [\n",
    "    ('LAYUP_ROOM', 'LAYUP_BOT_01', 'ENV_INFLUENCE', 0.8, 0),\n",
    "    ('LAYUP_ROOM', 'LAYUP_BOT_02', 'ENV_INFLUENCE', 0.8, 0),\n",
    "    ('LAYUP_BOT_01', 'AUTOCLAVE_01', 'MATERIAL_FLOW', 1.0, 2),\n",
    "    ('LAYUP_BOT_02', 'AUTOCLAVE_02', 'MATERIAL_FLOW', 1.0, 2),\n",
    "    ('AUTOCLAVE_01', 'CNC_MILL_01', 'MATERIAL_FLOW', 1.0, 4),\n",
    "    ('AUTOCLAVE_02', 'CNC_MILL_02', 'MATERIAL_FLOW', 1.0, 4),\n",
    "    ('CNC_MILL_01', 'QC_STATION_01', 'MATERIAL_FLOW', 1.0, 1),\n",
    "    ('CNC_MILL_02', 'QC_STATION_02', 'MATERIAL_FLOW', 1.0, 1),\n",
    "]\n",
    "\n",
    "edge_index = torch.tensor([\n",
    "    [ASSET_TO_IDX[src] for src, _, _, _, _ in EDGES],\n",
    "    [ASSET_TO_IDX[tgt] for _, tgt, _, _, _ in EDGES]\n",
    "], dtype=torch.long)\n",
    "\n",
    "print(f\"Nodes: {len(ASSETS)}, Edges: {edge_index.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "synthetic_data_header"
   },
   "source": [
    "## 2. Generate Synthetic Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "generate_features_cell"
   },
   "outputs": [],
   "source": [
    "def generate_node_features(num_samples=1000, feature_dim=8):\n",
    "    \"\"\"Generate synthetic node features with humidity-scrap correlation.\"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        features = np.zeros((len(ASSETS), feature_dim))\n",
    "        labels = np.zeros(len(ASSETS))\n",
    "        \n",
    "        for i in range(len(ASSETS)):\n",
    "            features[i] = [np.random.uniform(0.6, 1.0), 0] + list(np.random.normal(0.5, 0.15, 6).clip(0, 1))\n",
    "        \n",
    "        # Humidity-scrap correlation: high humidity leads to downstream anomalies\n",
    "        if features[0, 2] > 0.65:\n",
    "            labels[3] = 1 if np.random.random() < 0.48 else 0  # AUTOCLAVE_01\n",
    "            labels[4] = 1 if np.random.random() < 0.48 else 0  # AUTOCLAVE_02\n",
    "        \n",
    "        X.append(features)\n",
    "        y.append(labels)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = generate_node_features(800)\n",
    "X_val, y_val = generate_node_features(100)\n",
    "X_test, y_test = generate_node_features(100)\n",
    "\n",
    "print(f\"Training: {X_train.shape[0]}, Validation: {X_val.shape[0]}, Test: {X_test.shape[0]}\")\n",
    "print(f\"Anomaly rate: {y_train.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "gnn_model_header"
   },
   "source": [
    "## 3. Define GNN Model (GraphSAGE with Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "model_definition_cell"
   },
   "outputs": [],
   "source": [
    "class AssetGNN(nn.Module):\n",
    "    \"\"\"GraphSAGE model for anomaly propagation prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, node_features=8, hidden_dim=64, output_dim=1, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(node_features, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.attention = nn.MultiheadAttention(hidden_dim, num_heads=4, dropout=dropout, batch_first=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2), nn.ReLU(),\n",
    "            nn.Dropout(dropout), nn.Linear(hidden_dim // 2, output_dim)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.dropout(F.relu(self.conv1(x, edge_index)))\n",
    "        x = self.dropout(F.relu(self.conv2(x, edge_index)))\n",
    "        x_attended, _ = self.attention(x.unsqueeze(0), x.unsqueeze(0), x.unsqueeze(0))\n",
    "        return torch.sigmoid(self.classifier(x_attended.squeeze(0)))\n",
    "\n",
    "model = AssetGNN()\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "training_header"
   },
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "training_loop_cell"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "edge_index = edge_index.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.0]).to(device))\n",
    "\n",
    "train_losses = []\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i in range(len(X_train)):\n",
    "        x = torch.tensor(X_train[i], dtype=torch.float).to(device)\n",
    "        target = torch.tensor(y_train[i], dtype=torch.float).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(x, edge_index).squeeze(), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    train_losses.append(epoch_loss / len(X_train))\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Loss = {train_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "visualization_header"
   },
   "source": [
    "## 5. Anomaly Propagation Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "test_propagation_cell"
   },
   "outputs": [],
   "source": [
    "# Test with high humidity scenario\n",
    "test_scenario = np.zeros((len(ASSETS), 8))\n",
    "for i in range(len(ASSETS)):\n",
    "    test_scenario[i] = [0.9, 0] + list(np.random.uniform(0.4, 0.6, 6))\n",
    "test_scenario[0, 2] = 0.72  # High humidity in Layup Room\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x = torch.tensor(test_scenario, dtype=torch.float).to(device)\n",
    "    probs = model(x, edge_index).squeeze().cpu().numpy()\n",
    "\n",
    "print(\"Anomaly Propagation Prediction (High Humidity):\")\n",
    "for asset, prob in zip(ASSETS, probs):\n",
    "    risk = \"HIGH\" if prob > 0.5 else \"MEDIUM\" if prob > 0.3 else \"LOW\"\n",
    "    print(f\"  {asset:20s}: {prob:.1%} ({risk})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "graph_visualization_cell"
   },
   "outputs": [],
   "source": [
    "# Visualize graph with propagation probabilities\n",
    "POSITIONS = {\n",
    "    'LAYUP_ROOM': (0, 1), 'LAYUP_BOT_01': (1, 0), 'LAYUP_BOT_02': (1, 2),\n",
    "    'AUTOCLAVE_01': (2, 0), 'AUTOCLAVE_02': (2, 2),\n",
    "    'CNC_MILL_01': (3, 0), 'CNC_MILL_02': (3, 2),\n",
    "    'QC_STATION_01': (4, 0), 'QC_STATION_02': (4, 2)\n",
    "}\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for src, tgt, _, _, _ in EDGES:\n",
    "    x0, y0 = POSITIONS[src]\n",
    "    x1, y1 = POSITIONS[tgt]\n",
    "    strength = max(probs[ASSET_TO_IDX[src]], probs[ASSET_TO_IDX[tgt]])\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[x0, x1], y=[y0, y1], mode='lines',\n",
    "        line=dict(color=f'rgba(255, {int(255*(1-strength))}, 100, {0.3 + strength*0.7})', width=2 + strength * 6),\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "for asset, (x, y) in POSITIONS.items():\n",
    "    prob = probs[ASSET_TO_IDX[asset]]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[x], y=[y], mode='markers+text',\n",
    "        marker=dict(size=50 + prob * 30, color=f'rgb({int(255*prob)}, {int(200*(1-prob))}, 100)'),\n",
    "        text=f\"{asset.replace('_', '<br>')}<br>{prob:.0%}\",\n",
    "        textfont=dict(size=9, color='white'), showlegend=False\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='GNN Anomaly Propagation (High Humidity Scenario)', template='plotly_dark', height=500,\n",
    "    xaxis=dict(showgrid=False, showticklabels=False), yaxis=dict(showgrid=False, showticklabels=False)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64afab28",
   "metadata": {
    "name": "snowflake_output_header"
   },
   "source": [
    "## 6. Write Propagation Scores to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13701deb",
   "metadata": {
    "name": "write_propagation_cell"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.context import get_active_session\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "session = get_active_session()\n",
    "run_timestamp = datetime.now()\n",
    "\n",
    "propagation_records = []\n",
    "\n",
    "for source_idx, source_asset in enumerate(ASSETS):\n",
    "    for target_idx, target_asset in enumerate(ASSETS):\n",
    "        if source_idx != target_idx:\n",
    "            edge_type = None\n",
    "            hop_distance = None\n",
    "            for src, tgt, etype, weight, lag in EDGES:\n",
    "                if src == source_asset and tgt == target_asset:\n",
    "                    edge_type = etype\n",
    "                    hop_distance = 1\n",
    "                    break\n",
    "            \n",
    "            source_prob = float(probs[source_idx])\n",
    "            target_prob = float(probs[target_idx])\n",
    "            prop_score = abs(target_prob - source_prob) if source_prob > 0.3 else 0.0\n",
    "            \n",
    "            if prop_score > 0.05 or edge_type:\n",
    "                propagation_records.append({\n",
    "                    'SOURCE_ASSET': source_asset,\n",
    "                    'TARGET_ASSET': target_asset,\n",
    "                    'PROPAGATION_SCORE': round(prop_score, 4),\n",
    "                    'PROPAGATION_TYPE': 'HUMIDITY_CASCADE' if source_asset == 'LAYUP_ROOM' else 'DOWNSTREAM',\n",
    "                    'EDGE_TYPE': edge_type,\n",
    "                    'HOP_DISTANCE': hop_distance if hop_distance else -1,\n",
    "                    'CONFIDENCE': round(float(source_prob), 4)\n",
    "                })\n",
    "\n",
    "print(f'Writing {len(propagation_records)} propagation scores to Snowflake...')\n",
    "prop_df = pd.DataFrame(propagation_records)\n",
    "session.write_pandas(prop_df, 'GNN_PROPAGATION_SCORES', database='SNOWCORE_PDM', schema='PDM', overwrite=False)\n",
    "print(f'  PDM.GNN_PROPAGATION_SCORES: {len(prop_df)} rows written')\n",
    "print('\\n[OK] GNN propagation scores saved to Snowflake')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
